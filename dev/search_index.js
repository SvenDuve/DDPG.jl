var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = DDPG","category":"page"},{"location":"#DDPG","page":"Home","title":"DDPG","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for DDPG.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [DDPG]","category":"page"},{"location":"#DDPG.action-NTuple{5, Any}","page":"Home","title":"DDPG.action","text":"action(model, state, train, ep, hp)\n\nReturns an action based on the current state, noise and the model.\n\n\n\n\n\n","category":"method"},{"location":"#DDPG.agent-Tuple{RLTypes.ContinuousEnvironment, RLTypes.AgentParameter}","page":"Home","title":"DDPG.agent","text":"agent(environment::ContinuousEnvironment, agentParams::AgentParameter)\n\nMain DDPG Algorithm to train an agent.\n\n\n\n\n\n","category":"method"},{"location":"#DDPG.setActor-Tuple{Any, Any}","page":"Home","title":"DDPG.setActor","text":"setActor(state_size, action_size)\n\nSet an actor model for the DDPG agent.\n\n\n\n\n\n","category":"method"},{"location":"#DDPG.setCritic-Tuple{Any, Any}","page":"Home","title":"DDPG.setCritic","text":"setCritic(state_size, action_size)\n\nSet a critic model for the DDPG agent.\n\n\n\n\n\n","category":"method"},{"location":"#DDPG.soft_update!-Tuple{Any, Any, Any}","page":"Home","title":"DDPG.soft_update!","text":"soft_update!(target_model, main_model, τ)\n\nSoft update of the target model.\n\n\n\n\n\n","category":"method"},{"location":"#DDPG.train_step!-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, RLTypes.Parameter}","page":"Home","title":"DDPG.train_step!","text":"train_step!(S, A, R, S´, T, μθ, μθ´, Qϕ, Qϕ´, opt_critic, opt_actor, ap::Parameter)\n\nTrain the DDPG agent with gradient descent.\n\n\n\n\n\n","category":"method"}]
}
